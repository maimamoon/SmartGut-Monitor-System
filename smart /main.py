from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import serial
import threading
import time
import torch
import torch.nn as nn
import numpy as np
import librosa

# ==========================================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
# ==========================================
app = FastAPI(title="Smart Gut AI Backend")

# Ø§Ù„Ø³Ù…Ø§Ø­ Ù„Ù„ÙØ±ÙˆÙ†Øª Ø¥Ù†Ø¯ Ø¥Ù†Ù‡ ÙŠÙƒÙ„Ù…Ù†Ø§ (CORS)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], 
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

SERIAL_PORT = 'COM3'   # âš ï¸ Ø§ØªØ£ÙƒØ¯ÙŠ Ù…Ù† Ø§Ù„Ø¨ÙˆØ±Øª Ø¨ØªØ§Ø¹Ùƒ
BAUD_RATE = 115200
SAMPLE_RATE = 4000     # Ù„Ø§Ø²Ù… ÙŠÙƒÙˆÙ† Ù…ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø³Ø±Ø¹Ø© Ø§Ù„Ù€ ESP

# Ù…ØªØºÙŠØ±Ø§Øª Ø¨ØªØ´ÙŠÙ„ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø±ÙŠØ¶ Ø§Ù„Ø­Ø§Ù„ÙŠØ© (Ø¹Ø´Ø§Ù† Ø§Ù„Ù€ API ÙŠÙ‚Ø±Ø£ Ù…Ù†Ù‡Ø§)
current_status = {
    "connection": False,
    "prediction": "Waiting...",  # Normal / Abnormal
    "confidence": 0.0,           # Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø©
    "is_sick": False             # Ø¹Ø´Ø§Ù† Ø§Ù„ÙØ±ÙˆÙ†Øª ÙŠØºÙŠØ± Ø§Ù„Ù„ÙˆÙ†
}

# ==========================================
# 2. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (ğŸ”¥ AI BRAIN STRUCTURE)
# ==========================================
# Ù‡Ø§Ù… Ø¬Ø¯Ø§Ù‹: Ù„Ø§Ø²Ù… Ø§Ù„ÙƒÙ„Ø§Ø³ Ø¯Ù‡ ÙŠÙƒÙˆÙ† Ù†Ø³Ø®Ø© Ø·Ø¨Ù‚ Ø§Ù„Ø£ØµÙ„ Ù…Ù† Ø§Ù„Ù„ÙŠ ÙÙŠ Colab
class CNN_MFCC(nn.Module):
    def __init__(self, num_classes=2):
        super(CNN_MFCC, self).__init__()
        # âš ï¸ Ø§Ù†Ø³Ø®ÙŠ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø¨ØªØ§Ø¹ØªÙƒ Ù‡Ù†Ø§
        self.features = nn.Sequential(
            nn.Conv2d(1, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2),
        )
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),
            nn.Dropout(0.5),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x

# ==========================================
# 3. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (ğŸ”¥ WAKING UP THE BRAIN)
# ==========================================
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = CNN_MFCC(num_classes=2).to(device)

try:
    # Ø­Ø§ÙˆÙ„ÙŠ ØªÙ†Ø²Ù„ÙŠ Ù…Ù„Ù Ø§Ù„Ø£ÙˆØ²Ø§Ù† ÙˆØªØ­Ø·ÙŠÙ‡ Ø¬Ù†Ø¨ Ø§Ù„ÙƒÙˆØ¯
    model.load_state_dict(torch.load('smart_gut_crnn.pth', map_location=device))
    model.eval() # ÙˆØ¶Ø¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± (Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹)
    print("âœ… AI Model Loaded Successfully!")
except Exception as e:
    print(f"âš ï¸ Warning: Model not found. Running in Demo Mode. Error: {e}")

# ==========================================
# 4. Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© (ğŸ”¥ PREPROCESSING)
# ==========================================
def preprocess_audio(raw_data):
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ù„Ù…ØµÙÙˆÙØ©
    y = np.array(raw_data, dtype=np.float32)
    
    # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„ØµÙˆØª (Normalization)
    if np.max(np.abs(y)) > 0:
        y = y / np.max(np.abs(y))
        
    # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ MFCC (Ù†ÙØ³ Ø·Ø±ÙŠÙ‚Ø© Colab)
    mfcc = librosa.feature.mfcc(y=y, sr=SAMPLE_RATE, n_mfcc=40)
    
    # ØªØ¸Ø¨ÙŠØ· Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø¹Ø´Ø§Ù† ØªØ¯Ø®Ù„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (Batch, Channel, Height, Width)
    mfcc_tensor = torch.tensor(mfcc).unsqueeze(0).unsqueeze(0).to(device)
    return mfcc_tensor

# ==========================================
# 5. Ø­Ù„Ù‚Ø© Ø§Ù„Ù‡Ø§Ø±Ø¯ÙˆÙŠØ± (The Engine)
# ==========================================
def background_loop():
    global current_status
    buffer = []
    frames_needed = int(SAMPLE_RATE * 2.0) # ØªØ­Ù„ÙŠÙ„ ÙƒÙ„ 2 Ø«Ø§Ù†ÙŠØ©

    while True:
        try:
            esp = serial.Serial(SERIAL_PORT, BAUD_RATE, timeout=0.1)
            current_status["connection"] = True
            
            while True:
                if esp.in_waiting > 0:
                    try:
                        line = esp.readline().decode('utf-8').strip()
                        if line.isdigit():
                            buffer.append(int(line))
                            
                            # Ø£ÙˆÙ„ Ù…Ø§ Ù†Ø¬Ù…Ø¹ Ù…Ù‚Ø·Ø¹ ÙƒØ§Ù…Ù„.. Ø´ØºÙ„ Ø§Ù„Ù€ AI
                            if len(buffer) >= frames_needed:
                                # 1. ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¯Ø§ØªØ§
                                input_tensor = preprocess_audio(buffer)
                                
                                # 2. ğŸ”¥ Ù„Ø­Ø¸Ø© Ø§Ù„ØªÙˆÙ‚Ø¹ (AI INFERENCE) ğŸ”¥
                                with torch.no_grad():
                                    output = model(input_tensor)
                                    probs = torch.nn.functional.softmax(output, dim=1)
                                    
                                    # Ø§ÙØªØ±Ø¶Ù†Ø§ Ø¥Ù† Ø§Ù„ÙƒÙ„Ø§Ø³ Ø±Ù‚Ù… 1 Ù‡Ùˆ "Ù…Ø±ÙŠØ¶"
                                    sick_prob = probs[0][1].item() 
                                
                                # 3. ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªÙŠØ¬Ø©
                                if sick_prob > 0.5:
                                    current_status["prediction"] = "Abnormal Sound Detected"
                                    current_status["is_sick"] = True
                                    current_status["confidence"] = round(sick_prob * 100, 1)
                                else:
                                    current_status["prediction"] = "Normal / Silence"
                                    current_status["is_sick"] = False
                                    current_status["confidence"] = round((1 - sick_prob) * 100, 1)
                                
                                # ØªÙØ±ÙŠØº Ø§Ù„Ø³Ù„Ø©
                                buffer = []
                                
                    except ValueError:
                        pass
                
        except serial.SerialException:
            current_status["connection"] = False
            current_status["prediction"] = "Sensor Disconnected"
            time.sleep(2) # Ø­Ø§ÙˆÙ„ ØªØ§Ù†ÙŠ Ø¨Ø¹Ø¯ Ø«Ø§Ù†ÙŠØªÙŠÙ†

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ù‡Ø§Ø±Ø¯ÙˆÙŠØ± ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©
thread = threading.Thread(target=background_loop, daemon=True)
thread.start()

# ==========================================
# 6. Ø¨ÙˆØ§Ø¨Ø© Ø§Ù„Ù€ API (Ù„Ù„ÙØ±ÙˆÙ†Øª Ø¥Ù†Ø¯)
# ==========================================
@app.get("/api/status")
def get_status():
    return current_status

# Ø§Ù„ØªØ´ØºÙŠÙ„: uvicorn main:app --reload